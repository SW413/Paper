\newpage
\section{Problem statement}
\label{sec:problem}

\myref{sub:gpubenchmark} shows that calculations on matrices, when sufficiently large, can take a long time to compute sequentially. 
Therefore it is smarter to parallelise the computations which can be, and even better to do so on a \acrshort{gpu} compared to a \acrshort{cpu}, due to its internal architecture. 
Many linear algebra calculations can be parallelised since it often contains large datasets where operations on the data does not depend on previous calculations. 
An example of this could be matrix calculations where most operations can be split into independent subproblems.
Therefore the computation time of these calculations can be significantly improved using the parallel computing capabilities on the \acrshort{gpu}, given the matrices are of sufficient size.

Writing programs which can be run on a \acrshort{gpu}, can be time consuming using the languages found in \myref{sec:state_of_the_art}.
Therefore we believe that more abstraction and less boilerplate when writing code to the \acrshort{gpu} would serve well and simplify the development for the people programming for the \acrshort{gpu}. 
In the rest of this paper, the following problem will be thoroughly investigated, not only in the design of the syntax and the semantics of the language, but also in the design of the compiler or interpreter.

\[
  \left[
  \begin{minipage}{\textwidth}
  \centering
  \begin{minipage}{0.96\textwidth}
  How does one design a programming language, with a corresponding compiler or interpreter, which compiles source code to execute on the \acrshort{gpu} at runtime for certain linear algebra calculations, such as matrix operations?
  %%How does one design a programming language, with a corresponding compiler, for technical computing that is capable of performing common operations of linear algebra, while targeting \acrshort{gpu}s as execution platform?
  
  %%Alternative%%
  %%How do you design a programming language and a compiler for this language, which is able to compute parallel linear algebra calculations using the \acrshort{gpu} instead of the CPU without the programmer specifying so?
  
  %%How would a programming language and a compiler be programmed for a language specific for computing paralles linear algebra calculations using the \acrshort{gpu} instead of the CPU without the programmer choosing so specifically.  

  %%Is it possible to design a programming language for numerical computation with a focus on matrices, which is simple to use but also fast by taking advantage of the \acrshort{gpu} on modern computers? How would such a language be implemented? 

  %%How can a simple programming language, which compiles code targeting the \acrshort{gpu}, be construed so it's easier to perform matrix calculations? 

  %%Is it possible to construct a programming language in which matrix operations and linear algebra can be performed, with the power of the \acrshort{gpu}, without the programmer having to worry about boilerplate code. 
  \end{minipage}
  \end{minipage}
    \right]
\]

Until it is decided whether an interpreter or a compiler will be made, they will be referred to as translators.