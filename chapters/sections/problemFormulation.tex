\newpage
\section{Problem statement}
\label{sec:problem}

\myref{sub:gpubenchmark} shows that calculations on matrices, when sufficiently large, can take a long time to compute sequentially. 
Therefore it is smarter to parallelise these computations, and even better to do so on a \acrshort{gpu} compared to a \acrshort{cpu}, due to its internal architecture.
Many linear algebra calculations can be parallelised since it often contains large datasets where operations on the data does not depend on previous calculations. \todo{LIAL er nævnt meget pludseligt, et afsnit omkring scientific computing eller blot GPU egnede emner drejet ind på LIAL ville løse problemet før her i problem statement er det kun brugt en enkelt gang som eksempel}
An example of this could be matrix calculations where most operations can be split into independent sub calculations.
Therefore the computation time of these calculations can be significantly improved using the parallel computing capabilities on the \acrshort{gpu}, given the matrices are of sufficient size.

Writing programs which can be run on a \acrshort{gpu}, can be time consuming using the languages found in \myref{sec:state_of_the_art}.
It can be time consuming due to the difficulty of writing code in some of these languages like OpenCL C, and CUDA C.
Therefore we believe that more abstraction and less boilerplate when writing code to the \acrshort{gpu} would serve well and reduce the workload on the people programming for the \acrshort{gpu}.
In the rest of this paper, the following problem will be thoroughly investigated, not only in the design of the syntax and the semantics of the language, but also in the design of the compiler.\todo{Vi beslutter os allerede her for at lave en compiler? Skal vi ikke fjerne det og ændre det til noget med "the design of translating the code" eller noget? -Søren}

\[
  \left[
  \begin{minipage}{\textwidth}
  \centering
  \begin{minipage}{0.96\textwidth}
  How does one design a programming language, with a corresponding compiler, which compiles source code to execute on the \acrshort{gpu} at runtime for certain linear algebra calculations, such as matrix operations?
  %%How does one design a programming language, with a corresponding compiler, for technical computing that is capable of performing common operations of linear algebra, while targeting \acrshort{gpu}s as execution platform?
  
  %%Alternative%%
  %%How do you design a programming language and a compiler for this language, which is able to compute parallel linear algebra calculations using the \acrshort{gpu} instead of the CPU without the programmer specifying so?
  
  %%How would a programming language and a compiler be programmed for a language specific for computing paralles linear algebra calculations using the \acrshort{gpu} instead of the CPU without the programmer choosing so specifically.  

  %%Is it possible to design a programming language for numerical computation with a focus on matrices, which is simple to use but also fast by taking advantage of the \acrshort{gpu} on modern computers? How would such a language be implemented? 

  %%How can a simple programming language, which compiles code targeting the \acrshort{gpu}, be construed so it's easier to perform matrix calculations? 

  %%Is it possible to construct a programming language in which matrix operations and linear algebra can be performed, with the power of the \acrshort{gpu}, without the programmer having to worry about boilerplate code. 
  \end{minipage}
  \end{minipage}
    \right]
\]