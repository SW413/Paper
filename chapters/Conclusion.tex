\chapter{Conclusion} % (fold)
\label{cha:conclusion}
The problem statement stated for this project, \myref{sec:problem}, is as follows:

\[
  \left[
  \begin{minipage}{\textwidth}
  \centering
  \begin{minipage}{0.96\textwidth}
  How does one design a programming language, with a corresponding compiler or interpreter, which compiles source code to execute on the \acrshort{gpu} at runtime for certain linear algebra calculations, such as matrix operations?
  \end{minipage}
  \end{minipage}
    \right]
\]

During the project different aspects of the process of creating a language and a compiler or interpreter have been presented; different ways of handling these aspects have been discussed as well as the implementation of these.
The language \gls{gamble} was designed to make it easier for programmers and mathematicians alike to perform matrix and vector computations that used the power of the \acrshort{gpu} without the programmer needing to specify so in the source code.
It was chosen that a compiler would be the best fit for translating the \gls{gamble} language.
Using the operators, defined in \myref{subsec:operators}, along with matrices or vectors \gls{gamble} will compile to OpenCL C code, which runs the computations on the \acrshort{gpu}.
As a result of running computations on the \acrshort{gpu} an increase in runtime efficiency can be obtained; an increase in runtime efficiency will only exist if the computations are of a significant size; \myref{cha:test_of_language} shows what data size is required for \gls{gamble} to provide an increase in runtime efficiency by using the \acrshort{gpu} rather than the sequential execution on the \acrshort{cpu}.

\myref{cha:language_criteria} mentions the criteria that the project group set for \gls{gamble} and what became its compiler; based on the test of \gls{gamble} it was concluded that \gls{gamble} can run faster than the sequential C code, at least for the operations \gls{gamble} performs on the \acrshort{gpu}.
The way \gls{gamble} is designed, this happens seamlessly to the programmer which was also a criterion for the language.
When the \acrshort{gpu} usage happens seamlessly it increases both the read- and writability of the language, because of the removal of all the boiler-plate code needed for executing on the \acrshort{gpu}.
Another criterion was to implement an error reporting system which would give descriptive error messages to ease the debugging of programs compiled by the compiler.
This is done by making a number of standard error classes for scope and type checking, and creating instances of these when encountering a corresponding error in the \acrshort{ast} in the contextual analysis phase, and continuing the scope and type checking until completion.
When the phase is complete the compiler will have a list of all the errors encountered and can print these in the console with the type of error and also the line number where the error occurs.
Another result of the contextual analysis phase is that it makes sure that programs written in \gls{gamble} and compiled by the \gls{gamble} compiler will run reliably according to the scope and type rules of \gls{gamble}.

For creating the parser for the compiler, the parser generator \acrshort{antlr}4 was used.
\acrshort{antlr}4 made a parser from the \acrshort{cfg} specified by the project group.
This parser generates a parse tree; the parse tree is translated into an \acrshort{ast} by the compiler.
The \acrshort{ast} removes redundant information from the parse tree thus simplifying its traversal.
The \acrshort{ast} allowed for easier access to the nodes than the parse tree, while grouping information and using less nodes for information compared to the parse tree.
Scope and type checking are essential parts of the compiler and identifies errors in the source code before runtime.

The project showed that there are many aspects in creating a language and a compiler.
The use of the \acrshort{gpu} is worthwhile when the size of the computations become sufficiently large, and creators of new languages or compilers should think of including ways of using this resource for such purposes.
Furthermore it became evident that attempting a general solution for all \acrshort{gpu} platforms is not the best approach, it would be better to spend the proper amount of time developing for each individual platform, if that time is available.

Based on the test of the language using the compiler and the fact that it upholds all the criteria stated by the project group, it is concluded that the solution is satisfactory.
The usage of an iterative development method has proven to be a good choice for the project group as it allowed the group to change and add features as the project progressed and more knowledge was acquired.
However the knowledge of OpenCL's limitations was acquired too late, and there was not enough time for the group to switch to CUDA before the project deadline.
The choice of a modular compiler design would make the switch to CUDA C or any other target language simpler and easier.