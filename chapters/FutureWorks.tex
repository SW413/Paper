\chapter{Future Works}\label{cha:future_works}
While the language and compiler functionality met the requirements set up earlier in this paper, there still exists room for improvements which could benefit both \gls{gamble} and its compiler.
In this chapter some of the possible expansions, i.e. new features and faster runtime execution, will be discussed.

\section{Linear Algebra}\label{improve:LIAL}
%More operations
%More algortihms
During development of \gls{gamble} the focus have been on matrix operations to be used in linear algebra.
As such incorporating more operations such as finding the inverse matrix, would remove the necessity of the programmers themselves having to develop functions to do so.
Moreover this would make it easier to implement algorithms which makes use of such operations.
Further development could also include some common algorithms e.g. Gaussian elimination.
As a result of how the \acrshort{gpu} is used in the current version of \gls{gamble}, the functions used by the programmer, may very well use the \acrshort{gpu} but not as effectively as it could e.g. if the functions has a multiple of matrix operations which could be collected into one kernel, removing some of the overhead.
Therefore making these improvements to the core language, would not only increase the writability of \gls{gamble}, but also increase the overall performance on run-time.

\section{Analysis for Platform Targeting}
%A more dynamic use of GPU through analysis
%Use GPU for more than matrix and vector operations
As aforementioned \gls{gamble} performs all operations using matrices and vectors on the \acrshort{gpu}.
While this should be sufficient for computations on big sets of data as the language has targeted, this is not advantageous for smaller matrices as shown in \myref{cha:test_of_language}.
A possible expansion would be to increase runtime efficiency further to only utilise the \acrshort{gpu} when an increase in performance is to be expected from doing so.
An analysis of the amount of computations required as well as the hardware available, would help towards gaining the best performance possible.
Even further development should also make it so more than just performing matrix and vector operations on the \acrshort{gpu} is possible.
This was chosen because all operations currently implemented towards matrix and vector operations are paralleliseable.
If implementing new operations and functions one must consider whether these benefit from the use on the \acrshort{gpu} or not.
Rather than blindly disregarding loops one could have the compiler check whether or not the loop in question could be parallelised, and perhaps perform some of the tools for increasing its runtime efficiency as mentioned in \myref{subsec:runtime} upon said loop.
 
\section{Kernel Memory Efficiency}
%Kernal optimisation
When creating kernels one must allocate memory within the memory hierarchy established in the OpenCL framework. 
In this compiler all memory is allocated in global memory as it significantly simplifies the knowledge of the \acrshort{gpu} hardware and its memory hierarchy required to write kernels.
With a deeper understanding of how the different memory sections communicate, it is possible to increase performance by using the best suited part of the memory hierarchy. \citep{ocl_lecture3}

\section{Platform Specifications}
%Platform performance
While OpenCL is not machine dependent, which machine one is working on does change what version of OpenCL is supported, as well as how different work sizes and data types are handled.
An example would be that while AMD \acrshort{gpu}s have hardware which better supports single precision calculations compared to NVIDIA \acrshort{gpu}s where they only have double precision. \citep{CUDAOpenCLOptimisation}
Due to these discrepancies the same program and kernel may perform differently on \acrshort{gpu}s with the same specifications but from different vendors.
As such, different implementations depending on manufacturer and OpenCL support may vary in performance depending on the specific hardware.

\section{Research Fields}
%From LIAL to Scientific computing
While making it possible to perform linear algebra operations have been the focus of this compiler, this is not the only field of computing that can benefit from the computational powers of the \acrshort{gpu}.
Graph theory, molecular dynamics, computational chemistry and many other fields all include compute intensive simulations and number crunching, all of which use some form of linear algebra among others.
Further developing the language to fit yet another field would significantly increase the use for such a language in the scientific community.
As long as one can ensure that the computations required can in some form be parallelised such that the \acrshort{gpu} can be of use, this is a possible and large addition to the language.
Alternatively one could be content with adding new data types and operations for other fields and implement the field specific methods as libraries.
This would make the language usable by other fields, as the users would be able to implement the needed methods themselves.